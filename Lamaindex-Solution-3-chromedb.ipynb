{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e663ba6c-68ee-471c-bc45-7569ed5e896c",
   "metadata": {},
   "source": [
    "## LLamaindex - solution 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865810d8-d2e7-4d90-ae9e-94adbd764ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, Document, VectorStoreIndex, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "534a0876-fbef-4457-bf30-0c561eae1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = SimpleDirectoryReader(input_files=[\".\\data\\llama2.pdf\"])\n",
    "docs = loader.load_data()\n",
    "doc_text = \"\\n\\n\".join(d.get_content() for d in docs)\n",
    "docs = [Document(text=doc_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90c6db9-64d2-4b9c-b6b9-00f3b3792376",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = SentenceSplitter()\n",
    "nodes = parser.get_nodes_from_documents(docs)\n",
    "for idx, node in enumerate(nodes):\n",
    "    node.id_ = f\"node-{idx}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b40c7044-5bf1-4caf-b247-c33b15a70cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76dfec2-192c-458a-ac4c-036488142a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fc3a8-b327-47d6-b179-a7070ddbaaab",
   "metadata": {},
   "source": [
    "## ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "979ff7c2-343a-42ce-8b10-5d51e308971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert of existing embedding ID: node-0\n",
      "Insert of existing embedding ID: node-1\n",
      "Insert of existing embedding ID: node-2\n",
      "Insert of existing embedding ID: node-3\n",
      "Insert of existing embedding ID: node-4\n",
      "Insert of existing embedding ID: node-5\n",
      "Insert of existing embedding ID: node-6\n",
      "Insert of existing embedding ID: node-7\n",
      "Insert of existing embedding ID: node-8\n",
      "Insert of existing embedding ID: node-9\n",
      "Insert of existing embedding ID: node-10\n",
      "Insert of existing embedding ID: node-11\n",
      "Insert of existing embedding ID: node-12\n",
      "Insert of existing embedding ID: node-13\n",
      "Insert of existing embedding ID: node-14\n",
      "Insert of existing embedding ID: node-15\n",
      "Insert of existing embedding ID: node-16\n",
      "Insert of existing embedding ID: node-17\n",
      "Insert of existing embedding ID: node-18\n",
      "Insert of existing embedding ID: node-19\n",
      "Insert of existing embedding ID: node-20\n",
      "Insert of existing embedding ID: node-21\n",
      "Insert of existing embedding ID: node-22\n",
      "Insert of existing embedding ID: node-23\n",
      "Insert of existing embedding ID: node-24\n",
      "Insert of existing embedding ID: node-25\n",
      "Insert of existing embedding ID: node-26\n",
      "Insert of existing embedding ID: node-27\n",
      "Insert of existing embedding ID: node-28\n",
      "Insert of existing embedding ID: node-29\n",
      "Insert of existing embedding ID: node-30\n",
      "Insert of existing embedding ID: node-31\n",
      "Insert of existing embedding ID: node-32\n",
      "Insert of existing embedding ID: node-33\n",
      "Insert of existing embedding ID: node-34\n",
      "Insert of existing embedding ID: node-35\n",
      "Insert of existing embedding ID: node-36\n",
      "Insert of existing embedding ID: node-37\n",
      "Insert of existing embedding ID: node-38\n",
      "Insert of existing embedding ID: node-39\n",
      "Insert of existing embedding ID: node-40\n",
      "Insert of existing embedding ID: node-41\n",
      "Insert of existing embedding ID: node-42\n",
      "Insert of existing embedding ID: node-43\n",
      "Insert of existing embedding ID: node-44\n",
      "Insert of existing embedding ID: node-45\n",
      "Insert of existing embedding ID: node-46\n",
      "Insert of existing embedding ID: node-47\n",
      "Insert of existing embedding ID: node-48\n",
      "Insert of existing embedding ID: node-49\n",
      "Insert of existing embedding ID: node-50\n",
      "Insert of existing embedding ID: node-51\n",
      "Insert of existing embedding ID: node-52\n",
      "Insert of existing embedding ID: node-53\n",
      "Insert of existing embedding ID: node-54\n",
      "Insert of existing embedding ID: node-55\n",
      "Insert of existing embedding ID: node-56\n",
      "Insert of existing embedding ID: node-57\n",
      "Insert of existing embedding ID: node-58\n",
      "Insert of existing embedding ID: node-59\n",
      "Insert of existing embedding ID: node-60\n",
      "Insert of existing embedding ID: node-61\n",
      "Insert of existing embedding ID: node-62\n",
      "Insert of existing embedding ID: node-63\n",
      "Insert of existing embedding ID: node-64\n",
      "Insert of existing embedding ID: node-65\n",
      "Insert of existing embedding ID: node-66\n",
      "Insert of existing embedding ID: node-67\n",
      "Insert of existing embedding ID: node-68\n",
      "Insert of existing embedding ID: node-69\n",
      "Insert of existing embedding ID: node-70\n",
      "Insert of existing embedding ID: node-71\n",
      "Insert of existing embedding ID: node-72\n",
      "Insert of existing embedding ID: node-73\n",
      "Insert of existing embedding ID: node-74\n",
      "Insert of existing embedding ID: node-75\n",
      "Insert of existing embedding ID: node-76\n",
      "Insert of existing embedding ID: node-77\n",
      "Insert of existing embedding ID: node-78\n",
      "Insert of existing embedding ID: node-79\n",
      "Insert of existing embedding ID: node-80\n",
      "Insert of existing embedding ID: node-81\n",
      "Insert of existing embedding ID: node-82\n",
      "Insert of existing embedding ID: node-83\n",
      "Insert of existing embedding ID: node-84\n",
      "Insert of existing embedding ID: node-85\n",
      "Insert of existing embedding ID: node-86\n",
      "Insert of existing embedding ID: node-87\n",
      "Insert of existing embedding ID: node-88\n",
      "Insert of existing embedding ID: node-89\n",
      "Insert of existing embedding ID: node-90\n",
      "Add of existing embedding ID: node-0\n",
      "Add of existing embedding ID: node-1\n",
      "Add of existing embedding ID: node-2\n",
      "Add of existing embedding ID: node-3\n",
      "Add of existing embedding ID: node-4\n",
      "Add of existing embedding ID: node-5\n",
      "Add of existing embedding ID: node-6\n",
      "Add of existing embedding ID: node-7\n",
      "Add of existing embedding ID: node-8\n",
      "Add of existing embedding ID: node-9\n",
      "Add of existing embedding ID: node-10\n",
      "Add of existing embedding ID: node-11\n",
      "Add of existing embedding ID: node-12\n",
      "Add of existing embedding ID: node-13\n",
      "Add of existing embedding ID: node-14\n",
      "Add of existing embedding ID: node-15\n",
      "Add of existing embedding ID: node-16\n",
      "Add of existing embedding ID: node-17\n",
      "Add of existing embedding ID: node-18\n",
      "Add of existing embedding ID: node-19\n",
      "Add of existing embedding ID: node-20\n",
      "Add of existing embedding ID: node-21\n",
      "Add of existing embedding ID: node-22\n",
      "Add of existing embedding ID: node-23\n",
      "Add of existing embedding ID: node-24\n",
      "Add of existing embedding ID: node-25\n",
      "Add of existing embedding ID: node-26\n",
      "Add of existing embedding ID: node-27\n",
      "Add of existing embedding ID: node-28\n",
      "Add of existing embedding ID: node-29\n",
      "Add of existing embedding ID: node-30\n",
      "Add of existing embedding ID: node-31\n",
      "Add of existing embedding ID: node-32\n",
      "Add of existing embedding ID: node-33\n",
      "Add of existing embedding ID: node-34\n",
      "Add of existing embedding ID: node-35\n",
      "Add of existing embedding ID: node-36\n",
      "Add of existing embedding ID: node-37\n",
      "Add of existing embedding ID: node-38\n",
      "Add of existing embedding ID: node-39\n",
      "Add of existing embedding ID: node-40\n",
      "Add of existing embedding ID: node-41\n",
      "Add of existing embedding ID: node-42\n",
      "Add of existing embedding ID: node-43\n",
      "Add of existing embedding ID: node-44\n",
      "Add of existing embedding ID: node-45\n",
      "Add of existing embedding ID: node-46\n",
      "Add of existing embedding ID: node-47\n",
      "Add of existing embedding ID: node-48\n",
      "Add of existing embedding ID: node-49\n",
      "Add of existing embedding ID: node-50\n",
      "Add of existing embedding ID: node-51\n",
      "Add of existing embedding ID: node-52\n",
      "Add of existing embedding ID: node-53\n",
      "Add of existing embedding ID: node-54\n",
      "Add of existing embedding ID: node-55\n",
      "Add of existing embedding ID: node-56\n",
      "Add of existing embedding ID: node-57\n",
      "Add of existing embedding ID: node-58\n",
      "Add of existing embedding ID: node-59\n",
      "Add of existing embedding ID: node-60\n",
      "Add of existing embedding ID: node-61\n",
      "Add of existing embedding ID: node-62\n",
      "Add of existing embedding ID: node-63\n",
      "Add of existing embedding ID: node-64\n",
      "Add of existing embedding ID: node-65\n",
      "Add of existing embedding ID: node-66\n",
      "Add of existing embedding ID: node-67\n",
      "Add of existing embedding ID: node-68\n",
      "Add of existing embedding ID: node-69\n",
      "Add of existing embedding ID: node-70\n",
      "Add of existing embedding ID: node-71\n",
      "Add of existing embedding ID: node-72\n",
      "Add of existing embedding ID: node-73\n",
      "Add of existing embedding ID: node-74\n",
      "Add of existing embedding ID: node-75\n",
      "Add of existing embedding ID: node-76\n",
      "Add of existing embedding ID: node-77\n",
      "Add of existing embedding ID: node-78\n",
      "Add of existing embedding ID: node-79\n",
      "Add of existing embedding ID: node-80\n",
      "Add of existing embedding ID: node-81\n",
      "Add of existing embedding ID: node-82\n",
      "Add of existing embedding ID: node-83\n",
      "Add of existing embedding ID: node-84\n",
      "Add of existing embedding ID: node-85\n",
      "Add of existing embedding ID: node-86\n",
      "Add of existing embedding ID: node-87\n",
      "Add of existing embedding ID: node-88\n",
      "Add of existing embedding ID: node-89\n",
      "Add of existing embedding ID: node-90\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# load some documents\n",
    "# I have nodes already \n",
    "# documents = SimpleDirectoryReader(r\".\\data\\llama2.pdf\").load_data()\n",
    "\n",
    "# initialize client, setting path to save data\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# create collection\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "# assign chroma as the vector_store to the context\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# create your index\n",
    "index = VectorStoreIndex(\n",
    "    nodes, storage_context=storage_context, embed_model=HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "    # documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db026145-8586-4456-a7b9-7c94a3d4f601",
   "metadata": {},
   "source": [
    "### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f73a589-34c7-47ca-9ea2-d96c8a74f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42f2db25-96a5-4705-b559-347961470ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\\nthe BOLD dataset (race, religion, and gender). As LLMs are integrated and deployed, we look forward to\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines, and the techniques we use to mitigate safety risks. We employ a process similar to the general\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\\nSpecifically, we use the following techniques in safety fine-tuning:\\n1. Supervised Safety Fine-Tuning: We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\\nthe model to align with our safety guidelines even before RLHF, and thus lays the foundation for\\nhigh-quality human preference data annotation.\\n2. Safety RLHF: Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.\\n3. Safety Context Distillation: Finally, we refine our RLHF pipeline with context distillation (Askell\\net al., 2021b). This involves generating safer model responses by prefixing a prompt with a safety\\npreprompt, e.g.,“You are a safe and responsible assistant,”and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentiallydistillsthe safety preprompt (context) into the\\nmodel. We use a targeted approach that allows our safety reward model to choose whether to use\\ncontext distillation for each sample.\\n4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreate adversarial prompts along two dimensions: arisk category, or potential topic about which the LLM\\ncould produce unsafe content; and anattack vector, or question style to cover different varieties of prompts\\nthat could elicit bad model behaviors.\\nTheriskcategoriesconsideredcanbebroadlydividedintothefollowingthreecategories: illicitandcriminal\\nactivities(e.g., terrorism, theft, human trafficking);hateful and harmful activities(e.g., defamation, self-\\nharm, eating disorders, discrimination); andunqualified advice(e.g., medical advice, financial advice, legal\\n23\\n\\nadvice). The attack vectors explored consist of psychological manipulation (e.g., authority manipulation),\\nlogic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\\n(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.\\nWethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\\nsafetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\\nprovide additional information if possible. We also ask the annotators to avoid negative user experience\\ncategories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\\niteratively refined and revised to include newly identified risks.\\n4.2.2 Safety Supervised Fine-Tuning\\nIn accordance with the established guidelines from Section 4.2.1, we gather prompts and demonstrations\\nof safe model responses from trained annotators, and use the data for supervised fine-tuning in the same\\nmanner as described in Section 3.1. An example can be found in Table 5.\\nThe annotators are instructed to initially come up with prompts that they think could potentially induce\\nthe model to exhibit unsafe behavior, i.e., perform red teaming, as defined by the guidelines. Subsequently,\\nannotators are tasked with crafting a safe and helpful response that the model should produce.\\n4.2.3 Safety RLHF\\nWeobserveearlyinthedevelopmentof Llama 2-Chatthatitisabletogeneralizefromthesafedemonstrations\\ninsupervisedfine-tuning. Themodelquicklylearnstowritedetailedsaferesponses, addresssafetyconcerns,\\nexplain why the topic might be sensitive, and provide additional helpful information. In particular, when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = VectorIndexRetriever(index=index, similarity_top_k=1)\n",
    "nodes = retriever.retrieve(\"Can you tell me about the key concepts for safety finetuning\")\n",
    "nodes[0].get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b00a3-6ac2-42a2-abec-5b8db0fb5da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
