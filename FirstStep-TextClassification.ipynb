{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bfd8262-7bf1-4198-a5f3-eb0486c53ca9",
   "metadata": {},
   "source": [
    "## LLM App/Project - RAG testing / Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27adbc05-d5ea-4ee8-ace5-b16c1bdfaf49",
   "metadata": {},
   "source": [
    "### Steps: \n",
    "\n",
    "1. Create a chat classifier in lamaindex which based on the provided BBC headline classify it into one of the five news categories.\n",
    "2. Using the chat classifier from the first task, add output evaluation - consider a possiblity of adding the way of teaching/improving a chat output based on this information\n",
    "3. Write RAG - add some wiki documents (~ 20 documents) and evaluate the responses\n",
    "4. Experiment with different evaluation metrics\n",
    "5. Experiment with different RAG methodologies and use evaluation metrics to see different results they can provide\n",
    "\n",
    "Possible problems:\n",
    "- Gemini API restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b0d20c1-790d-44d8-aa76-85ec38c446a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = Gemini(\n",
    "    model=\"models/gemini-1.5-flash\",\n",
    "    api_key=GOOGLE_API_KEY  # uses GOOGLE_API_KEY env var by default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3713355f-50d1-4267-93f2-4c0a826ccf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Response: assistant: Okay, I'm ready. Please provide the headline.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\",\n",
    "        content=(\n",
    "            \"You are a text classifier specializing in BBC headlines. \"\n",
    "            \"I will provide you with a headline, and you will classify it into one of the following five categories: \"\n",
    "            \"business, entertainment, politics, sport, or tech. \"\n",
    "            \"Choose the category that best fits the headline. If a headline fits multiple categories, select the one most relevant. \"\n",
    "            \"Provide only the category name as the response, without any additional text.\"\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "resp = llm.chat(messages)\n",
    "print(f\"System Response: {resp}\")\n",
    "\n",
    "# Chat loop \n",
    "while True:\n",
    "    text_input = input(\"User: \")\n",
    "    if text_input.lower() == \"exit\":\n",
    "        print(\"Exiting classifier. Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    messages.append(ChatMessage(role=\"user\", content=text_input))\n",
    "\n",
    "    response = str(llm.chat(messages))\n",
    "    messages.append(ChatMessage(role='assistant', content=response))    \n",
    "    print(f\"\\nChat: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9903641a-9b2f-4ebf-9eca-34b03687df41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
