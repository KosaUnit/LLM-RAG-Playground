{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2975470c-3ddc-4ceb-aafd-5a0418e6365e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a094379-8c90-4b1a-a133-30d3fb993e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = Gemini(\n",
    "    model=\"models/gemini-1.5-flash\",\n",
    "    api_key=GOOGLE_API_KEY  # uses GOOGLE_API_KEY env var by default\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da6df9-f6de-4f0f-a1d7-58a9ab2167b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7346b0e-ee3d-4be4-97c6-cdfc0192872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_info = \"\"\"\n",
    "The University of Washington, founded in 1861 in Seattle, is a public research university\n",
    "with over 45,000 students across three campuses in Seattle, Tacoma, and Bothell.\n",
    "As the flagship institution of the six public universities in Washington state,\n",
    "UW encompasses over 500 buildings and 20 million square feet of space,\n",
    "including one of the largest library systems in the world.\n",
    "\"\"\"\n",
    "\n",
    "wsu_info = \"\"\"\n",
    "Washington State University, commonly known as WSU, founded in 1890, is a public research university in Pullman, Washington.\n",
    "With multiple campuses across the state, it is the state's second largest institution of higher education.\n",
    "WSU is known for its programs in veterinary medicine, agriculture, engineering, architecture, and pharmacy.\n",
    "\"\"\"\n",
    "\n",
    "seattle_info = \"\"\"\n",
    "Seattle, a city on Puget Sound in the Pacific Northwest, is surrounded by water, mountains and evergreen forests, and contains thousands of acres of parkland.\n",
    "It's home to a large tech industry, with Microsoft and Amazon headquartered in its metropolitan area.\n",
    "The futuristic Space Needle, a legacy of the 1962 World's Fair, is its most iconic landmark.\n",
    "\"\"\"\n",
    "\n",
    "starbucks_info = \"\"\"\n",
    "Starbucks Corporation is an American multinational chain of coffeehouses and roastery reserves headquartered in Seattle, Washington.\n",
    "As the world's largest coffeehouse chain, Starbucks is seen to be the main representation of the United States' second wave of coffee culture.\n",
    "\"\"\"\n",
    "\n",
    "newzealand_info = \"\"\"\n",
    "New Zealand is an island country located in the southwestern Pacific Ocean. It comprises two main landmassesâ€”the North Island and the South Islandâ€”and over 700 smaller islands.\n",
    "The country is known for its stunning landscapes, ranging from lush forests and mountains to beaches and lakes. New Zealand has a rich cultural heritage, with influences from \n",
    "both the indigenous MÄori people and European settlers. The capital city is Wellington, while the largest city is Auckland. New Zealand is also famous for its adventure tourism,\n",
    "including activities like bungee jumping, skiing, and hiking.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc930acf-eeb1-48a5-a355-bb1c8d0c3177",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fb11e35-2bee-44e0-8f34-c20a737f716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import\n",
    "# import chromadb.utils.embedding_functions as embedding_functions\n",
    "\n",
    "# # use directly\n",
    "# google_ef  = embedding_functions.GoogleGenerativeAiEmbeddingFunction(api_key=GOOGLE_API_KEY)\n",
    "# google_ef([\"document1\",\"document2\"])\n",
    "\n",
    "# # pass documents to query for .add and .query\n",
    "# collection = client.create_collection(name=\"name\", embedding_function=google_ef)\n",
    "# collection = client.get_collection(name=\"name\", embedding_function=google_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35102d64-d68e-4f55-869e-7cd3af970403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import GoogleGenerativeAiEmbeddingFunction\n",
    "\n",
    "embedding_function = GoogleGenerativeAiEmbeddingFunction(\n",
    "    api_key=GOOGLE_API_KEY,\n",
    "    # model_name=\"text-embedding-ada-002\",\n",
    ")\n",
    "\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "vector_store = chroma_client.get_or_create_collection(\n",
    "    name=\"Washington\", embedding_function=embedding_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e87a321-b44e-4109-a960-38acb15af701",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(\"uw_info\", documents=uw_info)\n",
    "vector_store.add(\"wsu_info\", documents=wsu_info)\n",
    "vector_store.add(\"seattle_info\", documents=seattle_info)\n",
    "vector_store.add(\"starbucks_info\", documents=starbucks_info)\n",
    "vector_store.add(\"newzealand_info\", documents=newzealand_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c47c2f3-eec9-4e69-be01-f38b16839ad3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Build RAG from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02012a7b-8fed-419a-80cd-390e22e7a2b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from trulens.apps.custom import instrument\n",
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f4533-d6ec-4dd7-a5aa-e944daefd36e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "oai_client = OpenAI()\n",
    "\n",
    "\n",
    "class RAG:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(query_texts=query, n_results=4)\n",
    "        # Flatten the list of lists into a single list\n",
    "        return [doc for sublist in results[\"documents\"] for doc in sublist]\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        if len(context_str) == 0:\n",
    "            return \"Sorry, I couldn't find an answer to your question.\"\n",
    "\n",
    "        completion = (\n",
    "            oai_client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"We have provided context information below. \\n\"\n",
    "                        f\"---------------------\\n\"\n",
    "                        f\"{context_str}\"\n",
    "                        f\"\\n---------------------\\n\"\n",
    "                        f\"First, say hello and that you're happy to help. \\n\"\n",
    "                        f\"\\n---------------------\\n\"\n",
    "                        f\"Then, given this information, please answer the question: {query}\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            .choices[0]\n",
    "            .message.content\n",
    "        )\n",
    "        if completion:\n",
    "            return completion\n",
    "        else:\n",
    "            return \"Did not find an answer.\"\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query=query)\n",
    "        completion = self.generate_completion(\n",
    "            query=query, context_str=context_str\n",
    "        )\n",
    "        return completion\n",
    "\n",
    "\n",
    "rag = RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6804345-7707-4b61-85e0-f8c8e59cbd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decorating <function RAG.retrieve at 0x00000140692B2AC0>\n",
      "decorating <function RAG.generate_completion at 0x00000140692B28E0>\n",
      "decorating <function RAG.query at 0x00000140692B27A0>\n",
      "adding method <class '__main__.RAG'> retrieve __main__\n",
      "adding method <class '__main__.RAG'> generate_completion __main__\n",
      "adding method <class '__main__.RAG'> query __main__\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Initialize the client with your Gemini API key\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "\n",
    "class RAG:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(query_texts=query, n_results=4)\n",
    "        # Flatten the list of lists into a single list\n",
    "        return [doc for sublist in results[\"documents\"] for doc in sublist]\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        if len(context_str) == 0:\n",
    "            return \"Sorry, I couldn't find an answer to your question.\"\n",
    "\n",
    "        response = genai.generate_text(\n",
    "            model=\"gemini-1.5-flash\",\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"We have provided context information below. \\n\"\n",
    "                    f\"---------------------\\n\"\n",
    "                    f\"{context_str}\"\n",
    "                    f\"\\n---------------------\\n\"\n",
    "                    f\"First, say hello and that you're happy to help. \\n\"\n",
    "                    f\"\\n---------------------\\n\"\n",
    "                    f\"Then, given this information, please answer the question: {query}\",\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "        completion = response.result\n",
    "        if completion:\n",
    "            return completion\n",
    "        else:\n",
    "            return \"Did not find an answer.\"\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query=query)\n",
    "        completion = self.generate_completion(\n",
    "            query=query, context_str=context_str\n",
    "        )\n",
    "        return completion\n",
    "\n",
    "\n",
    "rag = RAG()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a121fff-fff0-4ed0-8cc0-0fc482689617",
   "metadata": {},
   "source": [
    "## Set up feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03f88b-f628-4a62-bbed-288ab3e4f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "provider = OpenAI(model_engine=\"gpt-4\")\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    ")\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input()\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve.rets[:])\n",
    "    .aggregate(np.mean)  # choose a different aggregation method if you wish\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
