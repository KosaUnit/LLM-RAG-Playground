{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5eb5655-f9d6-43d9-86de-00aa3d317e4e",
   "metadata": {},
   "source": [
    "### ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5a7ec0-c2f2-48be-9487-0ecb772536a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = Gemini(\n",
    "    model=\"models/gemini-1.5-flash\",\n",
    "    api_key=GOOGLE_API_KEY  # uses GOOGLE_API_KEY env var by default\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1d9e8-b26f-4b3a-85ea-ecf0f045c8cb",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bcbb7c3-a6fd-4fd3-a1ff-ff77ab7e421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "CHROMA_DATA_PATH = \"chroma_data/\"\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "COLLECTION_NAME = \"ex1\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=CHROMA_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a41708c9-dde2-4668-86f0-ad02b04f658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=EMBED_MODEL\n",
    ")\n",
    "\n",
    "collection = client.create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    embedding_function=embedding_func,\n",
    "    metadata={\"hnsw:space\": \"cosine\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8abc390b-bb79-4d48-a97f-05a73a466d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './data/Short_Stories'\n",
    "\n",
    "# Initialize variables\n",
    "documents = []  # To store the text content of each PDF\n",
    "ids = []  # To store the names of each PDF file\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):  # Check if the file is a TXT file\n",
    "        ids.append(file_name)  # Add the file name to the names list\n",
    "        file_path = os.path.join(folder_path, file_name)  # Full file path\n",
    "\n",
    "        # Read the TXT file content\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            txt_text = file.read()\n",
    "\n",
    "        documents.append(txt_text)  # Add the full text of the TXT file to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ab1c28-88f4-4a1a-bd9e-8f90529daed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=documents,\n",
    "    ids=ids\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e14cf8-d266-4f9e-af73-e8ba9ba43408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'embeddings', 'documents', 'uris', 'data', 'metadatas', 'distances', 'included'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results = collection.query(\n",
    "    query_texts=[\"Who had seven sons?\"],\n",
    "    n_results=1,\n",
    ")\n",
    "\n",
    "query_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88cd4969-34bf-488c-80ce-b3565cbce62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['019.txt']],\n",
       " [[\"There was once a man who had seven sons, and still he had\\nno daughter, however much he wished for one.  At length his\\nwife again gave him hope of a child, and when it came into\\nthe world it was a girl.  The joy was great, but the child was\\nsickly and small, and had to be privately baptized on account of\\nits weakness.  The father sent one of the boys in haste to the\\nspring to fetch water for the baptism.  The other six went with\\nhim, and as each of them wanted to be first to fill it, the jug\\nfell into the well.  There they stood and did not know what to do,\\nand none of them dared to go home.  As they still did not return,\\nthe father grew impatient, and said, they have certainly forgotten\\nit while playing some game, the wicked boys.  He became afraid that\\nthe girl would have to die without being baptized, and in his\\nanger cried, I wish the boys were all turned into ravens.  Hardly\\nwas the word spoken before he heard a whirring of wings over his\\nhead, looked up and saw seven coal-black ravens flying away.\\n\\nThe parents could not withdraw the curse, and however sad they\\nwere at the loss of their seven sons, they still to some extent\\ncomforted themselves with their dear little daughter, who soon\\ngrew strong and every day became more beautiful.  For a long time\\nshe did not know that she had had brothers, for her parents were\\ncareful not to mention them before her, but one day she\\naccidentally heard some people saying of herself, that the girl was\\ncertainly beautiful, but that in reality she was to blame for the\\nmisfortune which had befallen her seven brothers.  Then she was much\\ntroubled, and went to her father and mother and asked if it was\\ntrue that she had had brothers, and what had become of them.  The\\nparents now dared keep the secret no longer, but said that what\\nhad befallen her brothers was the will of heaven, and that her\\nbirth had only been the innocent cause.  But the maiden took it to\\nheart daily, and thought she must save her brothers.  She had no\\nrest or peace until she set out secretly, and went forth into the\\nwide world to search for her brothers and set them free, let it\\ncost what it might.  She took nothing with her but a little ring\\nbelonging to her parents as a keepsake, a loaf of bread against\\nhunger, a little pitcher of water against thirst, and a little\\nchair as a provision against weariness.\\n\\nAnd now she went continually onwards, far, far to the very end of\\nthe world.  Then she came to the sun, but it was too hot and\\nterrible, and devoured little children.  Hastily she ran away, and\\nran to the moon, but it was far too cold, and also awful and\\nmalicious, and when it saw the child, it said, I smell, I smell\\nthe flesh of men.  At this she ran swiftly away, and came to the\\nstars, which were kind and good to her, and each of them sat on its\\nown particular little chair.  But the morning star arose, and gave\\nher the drumstick of a chicken, and said, if you have not that\\ndrumstick you can not open the glass mountain, and in the glass\\nmountain are your brothers.\\n\\nThe maiden took the drumstick, wrapped it carefully in a cloth,\\nand went onwards again until she came to the glass mountain.  The\\ndoor was shut, and she thought she would take out the drumstick.\\nBut when she undid the cloth, it was empty, and she had lost the\\ngood star's present.  What was she now to do.  She wished to rescue\\nher brothers, and had no key to the glass mountain.  The good\\nsister took a knife, cut off one of her little fingers, put it in\\nthe door, and succeeded in opening it.  When she had gone inside, a\\nlittle dwarf came to meet her, who said, my child, what are you\\nlooking for.  I am looking for my brothers, the seven ravens, she\\nreplied.  The dwarf said, the lord ravens are not at home, but if\\nyou will wait here until they come, step in.  Thereupon the little\\ndwarf carried the ravens' dinner in, on seven little plates, and\\nin seven little glasses, and the little sister ate a morsel from\\neach plate, and from each little glass she took a sip, but in the\\nlast little glass she dropped the ring which she had brought away\\nwith her.\\n\\nSuddenly she heard a whirring of wings and a rushing through\\nthe air, and then the little dwarf said, now the lord ravens are\\nflying home.  Then they came, and wanted to eat and drink, and\\nlooked for their little plates and glasses.  Then said one after\\nthe other, who has eaten something from my plate.  Who has drunk\\nout of my little glass.  It was a human mouth.  And when the\\nseventh came to the bottom of the glass, the ring rolled against\\nhis mouth.  Then he looked at it, and saw that it was a ring\\nbelonging to his father and mother, and said, God grant that our\\nsister may be here, and then we shall be free.  When the maiden,\\nwho was standing behind the door watching, heard that wish,\\nshe came forth, and on this all the ravens were restored to their\\nhuman form again.  And they embraced and kissed each other,\\nand went joyfully home.\\n\"]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results['ids'], query_results[\"documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad910e-83d8-4d6d-ae7e-b96ad70aba2a",
   "metadata": {},
   "source": [
    "### RAG - shorter files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29bc7be-54c5-41f3-879e-ec8e5023ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from IPython.display import Markdown, display\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b6ce309-40bd-47cc-985d-957f791abfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73138163aabe4fd1b6cfa5833809d55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip.kosowski\\OneDrive - Accenture\\Desktop\\MyFolder\\Studying\\GenAi\\RAG_Testing\\vEnv\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\filip.kosowski\\AppData\\Local\\llama_index\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26c6a6fa7fe4d5b8ea561b0eddbe830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64b44826a5c40c6866cc72d860c78ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0870576f4d4b55b7ecb77f45169f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b568131561e74e438586a68de652acbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84da4577eb9440bb6f484e43571abad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b517c92caa8c42b8a6b99dcb688890f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1107bc134c49a19f32d692794c4955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8334bc2e8b4daea5df5e7dec9bd030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109cb7465170470a8ef63d57dbaa5b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5999924ab9d84996a40a6a0d72cb54d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'SimpleDirectoryReader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m HuggingFaceEmbedding(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# embed_model =  = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# load documents\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleDirectoryReader\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/Short_Stories/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# set up ChromaVectorStore and load in data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m ChromaVectorStore(chroma_collection\u001b[38;5;241m=\u001b[39mchroma_collection)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SimpleDirectoryReader' is not defined"
     ]
    }
   ],
   "source": [
    "# create client and a new collection\n",
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"quickstart\")\n",
    "\n",
    "# define embedding function\n",
    "embed_model = HuggingFaceEmbedding(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "# embed_model =  = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data/Short_Stories/\").load_data()\n",
    "\n",
    "# set up ChromaVectorStore and load in data\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae63c6-9c28-4a7e-a79b-3aad5de69c0b",
   "metadata": {},
   "source": [
    "# WHAT TO DO \n",
    "\n",
    "1. Check different embedding function\n",
    "2. It return to me the whole document instead of the interesting part of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f85dbc13-348a-48c5-9a8b-cfd13fb6be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd3ef7-e9e2-4d74-8395-ddd703727832",
   "metadata": {},
   "source": [
    "## Storing the vector index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa2d48-d668-4d17-b3fe-9c85e5780e1e",
   "metadata": {},
   "source": [
    "- https://docs.llamaindex.ai/en/stable/understanding/storing/storing/\n",
    "- https://realpython.com/chromadb-vector-database/ - good chromadb introduction\n",
    "- https://www.datacamp.com/tutorial/llama-index-adding-personal-data-to-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02347fcf-0f25-4864-a2c1-0b82d9d125e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
