{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5a7ec0-c2f2-48be-9487-0ecb772536a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = Gemini(\n",
    "    model=\"models/gemini-1.5-flash\",\n",
    "    api_key=GOOGLE_API_KEY  # uses GOOGLE_API_KEY env var by default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bcbb7c3-a6fd-4fd3-a1ff-ff77ab7e421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "CHROMA_DATA_PATH = \"chroma_data/\"\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "COLLECTION_NAME = \"ex1\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=CHROMA_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a41708c9-dde2-4668-86f0-ad02b04f658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=EMBED_MODEL\n",
    ")\n",
    "\n",
    "collection = client.create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    embedding_function=embedding_func,\n",
    "    metadata={\"hnsw:space\": \"cosine\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8abc390b-bb79-4d48-a97f-05a73a466d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './data/Short_Stories'\n",
    "\n",
    "# Initialize variables\n",
    "documents = []  # To store the text content of each PDF\n",
    "ids = []  # To store the names of each PDF file\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):  # Check if the file is a TXT file\n",
    "        ids.append(file_name)  # Add the file name to the names list\n",
    "        file_path = os.path.join(folder_path, file_name)  # Full file path\n",
    "\n",
    "        # Read the TXT file content\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            txt_text = file.read()\n",
    "\n",
    "        documents.append(txt_text)  # Add the full text of the TXT file to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ab1c28-88f4-4a1a-bd9e-8f90529daed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=documents,\n",
    "    ids=ids\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e14cf8-d266-4f9e-af73-e8ba9ba43408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'embeddings', 'documents', 'uris', 'data', 'metadatas', 'distances', 'included'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results = collection.query(\n",
    "    query_texts=[\"Find me some delicious food!\"],\n",
    "    n_results=1,\n",
    ")\n",
    "\n",
    "query_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88cd4969-34bf-488c-80ce-b3565cbce62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['027.txt']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results['ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae63c6-9c28-4a7e-a79b-3aad5de69c0b",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "1. Load raw data.\n",
    "2. Split it into chunks.\n",
    "3. Embed it using an embedding model.\n",
    "4. Store the embeddings in a vector store (e.g., ChromaDB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f85dbc13-348a-48c5-9a8b-cfd13fb6be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd3ef7-e9e2-4d74-8395-ddd703727832",
   "metadata": {},
   "source": [
    "## Storing the vector index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa2d48-d668-4d17-b3fe-9c85e5780e1e",
   "metadata": {},
   "source": [
    "- https://docs.llamaindex.ai/en/stable/understanding/storing/storing/\n",
    "- https://realpython.com/chromadb-vector-database/ - good chromadb introduction\n",
    "- https://www.datacamp.com/tutorial/llama-index-adding-personal-data-to-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02347fcf-0f25-4864-a2c1-0b82d9d125e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
